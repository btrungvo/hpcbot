[
    {
        "id": "../data/md/polaris/getting-started.md_0",
        "context": [
            "G",
            "Julia\n\nJulia is a high-level, high-performance dynamic programming language for technical computing. It has a syntax familiar to users of many other technical computing environments. Designed at MIT to tackle large-scale partial-differential equation simulation and distributed linear algebra, Julia features a robust ecosystem of tools for optimization, statistics, parallel programming, and data visualization. Julia is actively developed by the Julia Labs team at MIT and in industry, along with hundreds of domain-expert scientists and programmers worldwide.\n\nContributing\n\nThis guide is a first draft of the Julia documentation for Polaris. If you have any suggestions or contributions, please open a pull request or contact us by opening a ticket at the ALCF Helpdesk.\n\nJulia Installation\n\nWe encourage users interested in using Julia on Polaris to install in their home or project directories at this time. Using the official Julia 1.9 binaries from the Julia webpage is recommended. Juliaup provides a convenient way to install Julia and manage the various Julia versions. The default installation will install julia, juliaup, and other commands in a ${HOME}/.julia directory and update profile files like .bashrc to update PATH to include that directory. One can customize the installation to change these defaults.\n\nbash module load craype-accel-nvidia80 curl -fsSL https://install.julialang.org | sh",
            "!!! example \"Launching DeepSpeed\"\n\n=== \"Launching with MPICH\"\n\n    1. Get total number of available GPUs:\n        1. Count number of lines in `$PBS_NODEFILE` (1 host per line)\n        2. Count number of GPUs available on current host\n        3. `#!bash NGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"`\n    ```bash\n    NHOSTS=$(wc -l < \"${PBS_NODEFILE}\")\n    NGPU_PER_HOST=$(nvidia-smi -L | wc -l)\n    NGPUS=\"$((${NHOSTS}*${NGPU_PER_HOST}))\"\n    ```\n\n    2. Launch with `mpiexec`:\n    ```bash\n    mpiexec \\\n      --verbose \\\n      --envall \\\n      -n \"${NGPUS}\" \\\n      --ppn \"${NGPU_PER_HOST}\" \\\n      --hostfile=\"${PBS_NODEFILE}\" \\\n      python3 \\\n        cifar10_deepspeed.py \\\n        --deepspeed_config ds_config.json\n    ```\n\n=== \"Launching with DeepSpeed\"\n\n    1. Create a DeepSpeed compliant `hostfile`, specifying the `hostname` and\n       number of GPUs (`slots`) for each of our available workers:\n    ```bash\n    cat $PBS_NODEFILE > hostfile\n    sed -e 's/$/ slots=4/' -i hostfile\n    ```\n\n    2. Create a `#!bash .deepspeed_env` containing the environment\n       variables our workers will need access to:\n    ```bash\n    echo \"PATH=${PATH}\" >> .deepspeed_env\n    echo \"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" >> .deepspeed_env\n    echo \"http_proxy=${http_proxy}\" >> .deepspeed_env\n    echo \"https_proxy=${https_proxy}\" >> .deepspeed_env\n    ```\n\n    !!! warning"
        ],
        "golden_context": "Getting Started on Polaris\n\nLogging Into Polaris\n\nTo log into Polaris: ssh <username>@polaris.alcf.anl.gov Then, type in the password from your CRYPTOCard/MobilePASS+ token.\n\nHardware Overview\n\nAn overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.\n\nCompiling Applications\n\nUsers are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.\n\nAccessing Additional Software\n\nIn addition to the Cray PE, ALCF installs software in /soft which can be accessed via module commands by altering your $MODULEPATH: module use /soft/modulefiles The available software can then be queried with module avail.\n\nAdditionally, a suite of software packages are provided via Spack deployments, detailed on the Spack PE page.\n\nSubmitting and Running Jobs\n\nUsers are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.\n\nLustre File Striping\n\nIn addition to the content above, here is a document on Lustre File Striping Basics.\n\nLustre File Striping Basics\n\nProxy\n\nIf the node you are on doesn’t have outbound network connectivity, add the following to your ~/.bash_profile file to access the proxy host.\n\n```bash\n\nproxy settings",
        "cot_answer": "To answer the question \"What is Polaris?\", I will follow these steps:\n\n1. Identify relevant information from the context that might help answer the question.\n\n##begin_quote## Getting Started on Polaris ##end_quote##\n\n2. Analyze the content of this section to see if it provides any clues about what Polaris is.\n\nThe title \"Getting Started on Polaris\" suggests that Polaris is a system or platform that users need to get started with, but it doesn't explicitly state what Polaris is.\n\n3. Look for other sections in the context that might provide more information about Polaris.\n\n##begin_quote## Hardware Overview ##end_quote##\n\nThis section talks about the compute node architecture of Polaris, which implies that Polaris is a system or platform that has hardware components.\n\n4. Check if there are any specific details mentioned about Polaris in this section.\n\nThe text mentions \"An overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.\" This suggests that Polaris is indeed a system, but it doesn't provide more information about what kind of system it is.\n\n5. Consider other sections in the context that might provide more clues about Polaris.\n\n##begin_quote## Accessing Additional Software ##end_quote##\n\nThis section talks about software available on Polaris, which implies that Polaris is a platform or system where users can access and use various software packages.\n\n6. Look for any specific details mentioned about Polaris in this section.\n\nThe text mentions \"In addition to the Cray PE, ALCF installs software in /soft which can be accessed via module commands by altering your $MODULEPATH: module use /soft/modulefiles\" This suggests that Polaris is a system where users can access and use various software packages.\n\n7. Based on the information gathered from the context, provide a final answer to the question \"What is Polaris?\"\n\n<ANSWER>: A system or platform where users can get started with, access additional software, and utilize hardware components for compute node architecture.",
        "answer": "A system or platform where users can get started with, access additional software, and utilize hardware components for compute node architecture.",
        "question": "What is Polaris?"
    },
    {
        "id": "../data/md/polaris/getting-started.md_0",
        "context": [
            "cd ${PBS_O_WORKDIR}\n\nmodule load cudatoolkit-standalone/11.4.4\n\npython benchmark.py --platform=CUDA --test=pme --precision=mixed --seconds=30 --heavy-hydrogens > test.output ```\n\nBuilding OpenMM from Source\n\nUpdate environment $ module load cudatoolkit-standalone/11.4.4 $ module load cray-python/3.9.12.1\n\nDownload OpenMM $ git checkout https://github.com/openmm/openmm.git $ cd openmm ; mkdir build\n\nDownload and build doxygen $ git clone https://github.com/doxygen/doxygen.git $ cd doxygen ; cmake ; make ; make install ; cd ../\n\nDownload and install swig in OpenMM directory. $ tar xzf swig-4.0.2.tar.gz $ cd swig-4.0.2 $ ./configure --prefix=/path-to/openmm/swig-4.0.2 ; make -j 8 ; make install\n\nBuild OpenMM $ cmake -DDOXYGEN_EXECUTABLE=/path-to/openmm/doxygen/bin/doxygen \\ -DSWIG_EXECUTABLE=/path-to/openmm/swig-4.0.2/bin/swig \\ -DCMAKE_INSTALL_PREFIX=/path-to/openmm/build \\ -DCUDA_HOME=/soft/compilers/cudatoolkit/cuda-11.4.4 \\ -DCUDA_INCLUDE_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/include \\ -DCUDA_LIB_DIR=/soft/compilers/cudatoolkit/cuda-11.4.4/lib64 $ make -j 8 $ make install\n\nValidate installation: if successful, then info on code version, platform types, CUDA initialization, and force error tolerance will be shown.\n\n$ cd /path-to/openmm/examples $ python -m openmm.testInstallation\n\nBenchmark testing using the PBS job script above.\n\n$ cd /path-to/openmm/examples $ qsub ./submit.sh",
            "Running Jobs on Polaris\n\nQueues\n\nThere are five production queues you can target in your qsub (-q <queue name>):\n\nQueue Name Node Min Node Max Time Min Time Max Notes debug 1 2 5 min 1 hr max 24 nodes in use by this queue ay any given time; Only 8 nodes are exclusive (see Note below) debug-scaling 1 10 5 min 1 hr max 1 job running/accruing/queued per-user prod 10 496 5 min 24 hrs Routing queue; See below preemptable 1 10 5 min 72 hrs Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Max 20 jobs running/accruing/queued per-project ; see Note below demand 1 56 5 min 1 hr By request only ; max 100 jobs running/accruing/queued per-project\n\nNote: Please be aware that jobs in the preemptable queue can be killed at any time if jobs are submitted to the demand queue. Jobs in the demand queue take priority over jobs in the preemptable queue. This means jobs in the preemptable queue may be preempted (killed without any warning) if there are jobs in the demand queue. Unfortunately, there's always an inherent risk of jobs being killed when using the preemptable queue. Please use the following command to view details of a queue: qstat -Qf <queuename>\n\nTo make your job re-runable add the following PBS directive: #PBS -r y This will ensure your job will restart once the demand job is complete.",
            "G"
        ],
        "golden_context": "Getting Started on Polaris\n\nLogging Into Polaris\n\nTo log into Polaris: ssh <username>@polaris.alcf.anl.gov Then, type in the password from your CRYPTOCard/MobilePASS+ token.\n\nHardware Overview\n\nAn overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.\n\nCompiling Applications\n\nUsers are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.\n\nAccessing Additional Software\n\nIn addition to the Cray PE, ALCF installs software in /soft which can be accessed via module commands by altering your $MODULEPATH: module use /soft/modulefiles The available software can then be queried with module avail.\n\nAdditionally, a suite of software packages are provided via Spack deployments, detailed on the Spack PE page.\n\nSubmitting and Running Jobs\n\nUsers are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.\n\nLustre File Striping\n\nIn addition to the content above, here is a document on Lustre File Striping Basics.\n\nLustre File Striping Basics\n\nProxy\n\nIf the node you are on doesn’t have outbound network connectivity, add the following to your ~/.bash_profile file to access the proxy host.\n\n```bash\n\nproxy settings",
        "cot_answer": "To determine the username for poliaris.alcf.anl.gov, we need to follow these steps:\n\n1. Look for a section in the context that mentions logging into Polaris. This is likely where the username will be mentioned.\n\n##begin_quote##\nLogging Into Polaris\nTo log into Polaris: ssh <username>@polaris.alcf.anl.gov Then, type in the password from your CRYPTOCard/MobilePASS+ token.\n##end_quote##\n\n2. Identify the part of the sentence that contains the username. In this case, it's the part before the \"@\" symbol.\n\n3. The username is therefore \"ssh <username>@polaris.alcf.anl.gov\". We need to extract the username from this sentence.\n\n4. Looking at the sentence more closely, we can see that the username is actually a placeholder for a variable, indicated by the angle brackets \"<\" and \">\".\n\n5. However, if we look at the surrounding context, we can find an example of how to fill in this placeholder with an actual username. The text says \"ssh <username>@polaris.alcf.anl.gov\", implying that you should replace \"<username>\" with your actual username.\n\n6. Unfortunately, the context does not provide a specific username for poliaris.alcf.anl.gov. However, based on the information provided, it seems likely that the username would be something like \"your_username\" or \"your_actual_username\".\n\n7. Since we don't have more information about the actual username, we can only make an educated guess.\n\nTherefore, my final answer is:\n\n<ANSWER>: your_username",
        "answer": "your_username",
        "question": "What is the username for poliaris.alcf.anl.gov?"
    },
    {
        "id": "../data/md/polaris/getting-started.md_0",
        "context": [
            "Click the Apply button\n\n6. Streamlines as Tubes\n\nThe streamlines are just that, lines. We can use the Tubes filter to represent them as 3D objects, rather than just lines. - With StreamTracer1selected in the Pipeline Browser, from the main menu select: Filters->Alphabetical->Tube - In the Object Inspector make sure the Properties tab is selected - The default value for the Radius is a bit too large for this data, let's set that value to 0 - Click the Apply button - Notice that the StreamLine1 object has automatically been hidden - There are many different ways to color these tubes - With Tubes1 selected, switch to the Display tab in the Object Inspector - The Color bydropdown lets you choose from a handful of different variables\n\n7. Cutting Planes (Slices)",
            "Compiling for GPUs\n\nIt is assumed the majority of applications to be built on Polaris will make use of the GPUs. As such, the craype-accel-nvidia80 module is in the default environment. This has the effect of the Cray compiler wrappers adding -gpu to the compiler invocation along with additional include paths and libraries. Additional compilers flags may be needed depending on the compiler and GPU programming model used (e.g. -cuda, -acc, or -mp=gpu).\n\nThis module also adds GPU Transport Layer (GTL) libraries to the link-line to support GPU-aware MPI applications.\n\nMan Pages\n\nFor additional information on the Cray wrappers, please refer to the man pages. man cc man CC man ftn",
            "G"
        ],
        "golden_context": "Getting Started on Polaris\n\nLogging Into Polaris\n\nTo log into Polaris: ssh <username>@polaris.alcf.anl.gov Then, type in the password from your CRYPTOCard/MobilePASS+ token.\n\nHardware Overview\n\nAn overview of the Polaris system including details on the compute node architecture is available on the Machine Overview page.\n\nCompiling Applications\n\nUsers are encouraged to read through the Compiling and Linking Overview page and corresponding pages depending on the target compiler and programming model.\n\nAccessing Additional Software\n\nIn addition to the Cray PE, ALCF installs software in /soft which can be accessed via module commands by altering your $MODULEPATH: module use /soft/modulefiles The available software can then be queried with module avail.\n\nAdditionally, a suite of software packages are provided via Spack deployments, detailed on the Spack PE page.\n\nSubmitting and Running Jobs\n\nUsers are encouraged to read through the Running Jobs with PBS at the ALCF page for information on using the PBS scheduler and preparing job submission scripts. Some example job submission scripts are available on the Example Job Scripts page as well.\n\nLustre File Striping\n\nIn addition to the content above, here is a document on Lustre File Striping Basics.\n\nLustre File Striping Basics\n\nProxy\n\nIf the node you are on doesn’t have outbound network connectivity, add the following to your ~/.bash_profile file to access the proxy host.\n\n```bash\n\nproxy settings",
        "cot_answer": "To log into Polaris, we need to follow these steps:\n\n1. First, we need to establish a connection to the Polaris system using SSH. This is done by typing `ssh <username>@polaris.alcf.anl.gov` in our terminal.\n\n##begin_quote##\nTo log into Polaris: ssh <username>@polaris.alcf.anl.gov\n##end_quote##\n\n2. Once we have established a connection, we need to authenticate ourselves using the password from our CRYPTOCard/MobilePASS+ token. This is done by typing in the password when prompted.\n\n##begin_quote##\nThen, type in the password from your CRYPTOCard/MobilePASS+ token.\n##end_quote##\n\nTherefore, the final answer is:\n\n<ANSWER>: ssh <username>@polaris.alcf.anl.gov, then type in the password from your CRYPTOCard/MobilePASS+ token.",
        "answer": "ssh <username>@polaris.alcf.anl.gov, then type in the password from your CRYPTOCard/MobilePASS+ token.",
        "question": "How do I log into Polaris?"
    }
]